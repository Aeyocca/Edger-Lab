#Duplication fate project, looking at expression patterns in duplicated genes with cleome as outgroup expression value, well looking at up / downregulation under stresses (determined by edgeR) as character states to reconstruct ancestral up/downregulation state to look for evidence of subfunctionalization. After the genes with differential response to stress have been identified, their conserved non-coding sequences (CNSs) will be examined, hopefully will be able to find enriched kmer which corresponds to stress responsive element to which TFs bind

12-28-17
Just got back from break, before break / during wrote script (sub_filter.pl) to parse a few files. Had already determined whether certain genes were up / downregulated in response to different stresses. Examined that set of files to create a file where each line lists a single cleome gene name that shows an informative expression change between cleome and two duplicated a. thaliana copies of a gene. Will use this file to extract CNSs for these genes and perform kmer enrichment.

I have comp_cold.txt created output from sub_filter.pl which has tab separated [at edgeR number] [at subgenome copy 1 exp diff value] [at subgenome copy 2 exp diff value] [cleome exp diff value]

I wrote summary_stats.pl to output the informative genes and also print to command line how many were printed, I guess I could combine this with the other script, but they are already separate, and this way incase we want to examine genes without the pattern we were looking for (ONLY 1 at copy sharing state with CV) we got the full list.

Lets fix sub_filter.pl to include a fifth and sixth column with the TAIR10 gene name and cleome ortholog gene name respectively.


$ ./sub_filter.pl -p temp.txt -i At-Index.txt -a AtAlpha_Cv_4KT.txt -t edgeR_Arabidopsis_ColdALL_05_OUT_DEG.csv -c edgeR_Cv_ColdALL_05_OUT_DEG.txt -e Cv_Control1-6_GeneID.csv -o comp_cold.txt
1400 lines were written to comp_cold.txt

33602 lines were read in the at exp file

$ ./summary_stats.pl -i comp_cold.txt -o inf_cold.txt
1400 genes were analyzed
361 genes were informative and written to inf_cold.txt

Make files for other treatments:

$ ./sub_filter.pl -p temp.txt -i At-Index.txt -a AtAlpha_Cv_4KT.txt -t edgeR_Arabidopsis_SaltALL_05_OUT_DEG.csv -c edgeR_Cv_SaltALL_05_OUT_DEG.txt -e Cv_Control1-6_GeneID.csv -o comp_salt.txt 
0 lines were written to comp_salt.txt

0 lines were read in the at exp file

oopsy, got some problems
I remember now,
************************IMPORTANT********************************
The files sent to me were written on pc, so they have DOS carriage returns. Only way I know to fix is to upload file to hpcc, because my terminal doesn't have the dos2unix command. Need to log onto dev node also,

$ ./sub_filter.pl -p temp.txt -i At-Index.txt -a AtAlpha_Cv_4KT.txt -t edgeR_Arabidopsis_SaltALL_05_OUT_DEG.csv -c edgeR_Cv_SaltALL_05_OUT_DEG.txt -e Cv_Control1-6_GeneID.csv -o comp_salt.txt
0 lines were written to comp_salt.txt

0 lines were read in the at exp file

I think there is some flag I need but I can't remember what it was, use vi instead:
:1,$s/^M/\r/g
(enter ^M by pressing ctl+v then enter)

there we go, that did it, only needed to edit the arabidopsis ones, I think the dos2unix without any flags worked on the cv ones

$ ./sub_filter.pl -p temp.txt -i At-Index.txt -a AtAlpha_Cv_4KT.txt -t edgeR_Arabidopsis_SaltALL_05_OUT_DEG.csv -c edgeR_Cv_SaltALL_05_OUT_DEG.txt -e Cv_Control1-6_GeneID.csv -o comp_salt.txt
1400 lines were written to comp_salt.txt

33602 lines were read in the at exp file


aeyocca@Larry /cygdrive/c/Users/aeyocca/Documents/1_MSU/Edger_Rotation_2017/edgeR
$ ./summary_stats.pl -i comp_salt.txt -o inf_salt.txt
1400 genes were analyzed
317 genes were informative and written to inf_salt.txt



$ ./sub_filter.pl -p temp.txt -i At-Index.txt -a AtAlpha_Cv_4KT.txt -t edgeR_Arabidopsis_MeJaALL_05_OUT_DEG.csv -c edgeR_Cv_MeJaALL_05_OUT_DEG.txt -e Cv_Control1-6_GeneID.csv -o comp_meja.txt
1400 lines were written to comp_meja.txt

33602 lines were read in the at exp file


aeyocca@Larry /cygdrive/c/Users/aeyocca/Documents/1_MSU/Edger_Rotation_2017/edgeR
$ ./summary_stats.pl -i comp_meja.txt -o inf_meja.txt
1400 genes were analyzed
121 genes were informative and written to inf_meja.txt


Whats the degree of overlap between these gene sets?

Next I want to look for enriched kmers in CNSs of stress responsive (both up and down reg) genes.
To do this, I need two bins for kmer enrichment: background bin with non-repsonsive gene CNSs and treatment bin with responsive CNSs.
Need: script that will look through a set of genes with exp response direction (comp_[stress].txt or inf_[stress].txt files) and output just a list of at geneIDs with 4 different files: 2 non responsive genes one paired with up / down reg. and 2 responsive genes, one up one down. Look at the conditionals in the script, will explain much better than I can with words. 
Run this script through the 3 stresses, and through both comp / inf files. should end up with 24 files (create separate directory for them)

*********NONUPs are genes with NO CHANGE in treatment, whose PARALOG is UP regulated in the treatment*************************


Then the hard part will be extracting CNSs but we can think about those later.

sub_kmer_en_input.pl
my $usage = "\n$0 -i <comparison / informative file> -a <at_[stress]_up_[comp/inf].txt> -b <at_[stress]_nonup_[comp/inf].txt> -c <at_[stress]_down_[comp/inf].txt> -d <at_[stress]_nondown_[comp/inf].txt> -w <at_duplication_file> -p <temp.txt> \n\n";

$ ./sub_kmer_en_input.pl -i comp_cold.txt -a at_cold_up_comp.txt -b at_cold_nonup_comp.txt -c at_cold_down_comp.txt -d at_cold_nondown_comp.txt -w AtAlpha_Cv_4KT.txt -p temp.txt

A total of:
First copy upregulated, second non-resp: 69
Second copy upregulated, first non-resp: 78
First copy downregulated, second non-resp: 98
Second copy downregulated, first non-resp: 115

$ ./sub_kmer_en_input.pl -i inf_cold.txt -a kmer_en/at_cold_up_inf.txt -b kmer_en/at_cold_nonup_inf.txt -c kmer_en/at_cold_down_inf.txt -d kmer_en/at_cold_nondown_inf.txt -w AtAlpha_Cv_4KT.txt -p temp.txt

A total of:
First copy upregulated, second non-resp: 69
Second copy upregulated, first non-resp: 77
First copy downregulated, second non-resp: 98
Second copy downregulated, first non-resp: 114

Thats pretty interesting, only 2 occurrences of at1/2 one zero, and cv opposite of non-zero value (if that makes sense: only 2 occurrences of 1 0 -1, 0 1 -1, -1 0 1, 0 -1 1) those 4 different possibilities, at random should occur 1400*(4/(3^3)) =~ 207 times

$ ./sub_kmer_en_input.pl -i comp_salt.txt -a kmer_en/at_salt_up_comp.txt -b kmer_en/at_salt_nonup_comp.txt -c kmer_en/at_salt_down_comp.txt -d kmer_en/at_salt_nondown_comp.txt -w AtAlpha_Cv_4KT.txt -p temp.txt

A total of:
First copy upregulated, second non-resp: 73
Second copy upregulated, first non-resp: 76
First copy downregulated, second non-resp: 75
Second copy downregulated, first non-resp: 99


aeyocca@Larry /cygdrive/c/Users/aeyocca/Documents/1_MSU/Edger_Rotation_2017/edgeR
$ ./sub_kmer_en_input.pl -i inf_salt.txt -a kmer_en/at_salt_up_inf.txt -b kmer_en/at_salt_nonup_inf.txt -c kmer_en/at_salt_down_inf.txt -d kmer_en/at_salt_nondown_inf.txt -w AtAlpha_Cv_4KT.txt -p temp.txt

A total of:
First copy upregulated, second non-resp: 73
Second copy upregulated, first non-resp: 75
First copy downregulated, second non-resp: 73
Second copy downregulated, first non-resp: 96

$ ./sub_kmer_en_input.pl -i comp_meja.txt -a kmer_en/at_meja_up_comp.txt -b kmer_en/at_meja_nonup_comp.txt -c kmer_en/at_meja_down_comp.txt -d kmer_en/at_meja_nondown_comp.txt -w AtAlpha_Cv_4KT.txt -p temp.txt

A total of:
First copy upregulated, second non-resp: 22
Second copy upregulated, first non-resp: 31
First copy downregulated, second non-resp: 26
Second copy downregulated, first non-resp: 41

$ ./sub_kmer_en_input.pl -i inf_meja.txt -a kmer_en/at_meja_up_inf.txt -b kmer_en/at_meja_nonup_inf.txt -c kmer_en/at_meja_down_inf.txt -d kmer_en/at_meja_nondown_inf.txt -w AtAlpha_Cv_4KT.txt -p temp.txt

A total of:
First copy upregulated, second non-resp: 22
Second copy upregulated, first non-resp: 31
First copy downregulated, second non-resp: 26
Second copy downregulated, first non-resp: 41



Now we need to go from list of gene IDs to one file with just a string of CNSs

12-29-17:

get the CNSs for the gene lists using make_kmer_files.pl

aeyocca@Larry /cygdrive/c/Users/aeyocca/Documents/1_MSU/Edger_Rotation_2017/edge                                                                                                                R
$ ./make_kmer_files.pl -i kmer_en/at_cold_up_comp.txt -o kmer_en/cns_sorted/at_cold_up_comp_cns.fa -c CNS_Brassicaceae_65K_4Alan.txt -p tempo.txt                                               
Number of CNSs written to output: 708

aeyocca@Larry /cygdrive/c/Users/aeyocca/Documents/1_MSU/Edger_Rotation_2017/edgeR
$ ./make_kmer_files.pl -i kmer_en/at_cold_nonup_comp.txt -o kmer_en/cns_sorted/at_cold_nonup_comp_cns.fa -c CNS_Brassicaceae_65K_4Alan.txt -p tempo.txt

Number of CNSs written to output: 492

aeyocca@Larry /cygdrive/c/Users/aeyocca/Documents/1_MSU/Edger_Rotation_2017/edgeR
$ ./make_kmer_files.pl -i kmer_en/at_cold_down_comp.txt -o kmer_en/cns_sorted/at_cold_down_comp_cns.fa -c CNS_Brassicaceae_65K_4Alan.txt -p tempo.txt

Number of CNSs written to output: 695

aeyocca@Larry /cygdrive/c/Users/aeyocca/Documents/1_MSU/Edger_Rotation_2017/edgeR
$ ./make_kmer_files.pl -i kmer_en/at_cold_nondown_comp.txt -o kmer_en/cns_sorted/at_cold_nondown_comp_cns.fa -c CNS_Brassicaceae_65K_4Alan.txt -p tempo.txt

Number of CNSs written to output: 786


Make table:
Stress	comp/inf	direction	Number written to output
cold	  comp    	up	      708
cold	  comp	    nonup	    492
cold  	comp	    down	    695
cold	  comp	    nondown	  786
cold	  inf	      up	      707
cold	  inf	      nonup	    487
cold	  inf	      down	    673
cold	  inf	      nondown	  769
salt	  comp	    up	      714
salt	  comp	    nonup	    514
salt	  comp	    down	    614
salt	  comp	    nondown	  552
salt	  inf	      up	      713
salt	  inf	      nonup	    509
salt	  inf	      down	    604
salt	  inf     	nondown	  532
meja	  comp	    up	      207
meja	  comp    	nonup	    198
meja	  comp	    down	    247
meja	  comp	    nondown	  221
meja	  inf	      up	      207
meja	  inf	      nonup	    198
meja	  inf     	down	    247
meja	  inf	      nondown  	221


Alriighty, lets hope jellyfish will read these correctly, looks like it does, write different scripts for 5,6,7mer to iterate through all files:

[yoccaala@dev-intel14 cns_sorted]$ qsub -t 1-24 -v INFILE=cns_files.txt jellyfish_5.sh
50809721[].mgr-04.i
50809916[].mgr-04.i

[yoccaala@dev-intel14 cns_sorted]$ qsub -t 1-24 -v INFILE=cns_files.txt jellyfish_6.sh
50809948[].mgr-04.i
[yoccaala@dev-intel14 cns_sorted]$ qsub -t 1-24 -v INFILE=cns_files.txt jellyfish_7.sh
50809949[].mgr-04.i

[yoccaala@dev-intel14 cns_sorted]$ qsub -t 1-24 -v INFILE=cns_files.txt jellyfish_6.sh
50810478[].mgr-04.i
[yoccaala@dev-intel14 cns_sorted]$ qsub -t 1-24 -v INFILE=cns_files.txt jellyfish_7.sh
50810479[].mgr-04.i


[yoccaala@dev-intel14 cns_sorted]$ qsub jellyfish_all_7.sh
50810495.mgr-04.i


make scatterplot data frames: make_scat_df.pl

[yoccaala@dev-intel14 jellyfish]$ qsub -t 1-18 -v INFILE=up_dump_files.txt make_scat_df_up.sh  50811560[].mgr-04.i
[yoccaala@dev-intel14 jellyfish]$ qsub -t 1-18 -v INFILE=down_dump_files.txt make_scat_df_down.sh
50811563[].mgr-04.i


1-2-18
the scat_dfs looked messed up for some since the jellyfish qsub files weren't exactly correct. Fixed those and restarted from jellyfish step:

[yoccaala@dev-intel14 cns_sorted]$ wc -l cns_files.txt
24 cns_files.txt
[yoccaala@dev-intel14 cns_sorted]$ qsub -t 1-24 -v INFILE=cns_files.txt jellyfish_5.sh
50937959[].mgr-04.i
[yoccaala@dev-intel14 cns_sorted]$ qsub -t 1-24 -v INFILE=cns_files.txt jellyfish_6.sh
50937970[].mgr-04.i
[yoccaala@dev-intel14 cns_sorted]$ qsub -t 1-24 -v INFILE=cns_files.txt jellyfish_7.sh
50937982[].mgr-04.i


[yoccaala@dev-intel14 jellyfish]$ qsub -t 1-18 -v INFILE=up_dump_files.txt make_scat_df_up.sh
50938481[].mgr-04.i
[yoccaala@dev-intel14 jellyfish]$ qsub -t 1-18 -v INFILE=down_dump_files.txt make_scat_df_down.sh
50938483[].mgr-04.i


make a script to make scatterplot dataframes comparing the percentage frequency of kmer in stress vs. overall kmer frequency. So need to run jellyfish on base cns file

jellyfish count -m 5 -s 100M -t 1 -o jellyfish/${NAME}binary_5.jf ${LINE}

jellyfish dump jellyfish/${NAME}binary_5.jf_0 > jellyfish/${NAME}dump_5.fa
my $usage = "\n$0 -i <jellyfish_dump.fa> -z <zero_exp_change_jellyfish_dump.fa> -o <at_[stress]_[up/down]_[comp/inf]_df.txt> -p <temp1.txt> -q <temp2.txt> \n\n";

[yoccaala@dev-intel14 jellyfish]$ qsub -t 1-12 -v INFILE=all_7_dump_files.txt make_scat_df_all_7.sh
50940545[].mgr-04.i
[yoccaala@dev-intel14 jellyfish]$ qsub -t 1-12 -v INFILE=all_6_dump_files.txt make_scat_df_all_6.sh
50940546[].mgr-04.i
[yoccaala@dev-intel14 jellyfish]$ qsub -t 1-12 -v INFILE=all_5_dump_files.txt make_scat_df_all_5.sh
50940548[].mgr-04.i

checked out all the scatter plots, not too much interesting. getting some signal from meja files, could be that they are messed up though... we shall see

at_salt_down_inf_dump_5.fa
at_meja_up_comp_dump_5.fa

at_meja_down_comp_dump_7_df.txt
TAAAGTA 7       0
AAACATT 7       1
AGACAAA 7       1


[yoccaala@dev-intel14 Permutations]$ qsub -t 1-1000 -v INFILE=perm_file_list.txt jellyfish_5.sh
50950625[].mgr-04.i


module load jellyfish

LINE=`/bin/sed -n ${PBS_ARRAYID}p ${INFILE}`

NAME=$(echo ${LINE} | sed 's/\.txt//')

jellyfish count -m 5 -s 100M -t 1 -o jellyfish/${NAME}binary_5.jf ${LINE}

jellyfish dump jellyfish/${NAME}binary_5.jf_0 > jellyfish/${NAME}.fa


[yoccaala@dev-intel14 Permutations]$ qsub -t 1-1000 -v INFILE=perm_file_list.txt jellyfish_5.sh
50950867[].mgr-04.i


[yoccaala@dev-intel14 kmer_en]$ qsub perm_kmer_con.sh
50961520.mgr-04.i
50964048.mgr-04.i
50964820.mgr-04.i
50965016.mgr-04.i
50965414.mgr-04.i
50965580.mgr-04.i
50966987.mgr-04.i

1-3-18

50981248.mgr-04.i
50981332.mgr-04.i
50981371.mgr-04.i
50981422.mgr-04.i
50981451.mgr-04.i
50981914.mgr-04.i
50982021.mgr-04.i
50982866.mgr-04.i
50983684.mgr-04.i
50983957.mgr-04.i

[yoccaala@dev-intel14 kmer_en]$ qsub perm_kmer_con_1.sh
50986540.mgr-04.i
50987822.mgr-04.i
50987926.mgr-04.i

1-7-18

[yoccaala@dev-intel14 jellyfish]$ qsub -t 1-1000 -v INFILE=fa_file_list.txt fa_to_one_liner.sh
51058722[].mgr-04.i
51059305[].mgr-04.i
51065779[].mgr-04.i

convert all to one liner, load into r to compile into one file, convert all the treatments to one line, use one line treatments and combined file in R to get file for each treatment with kmer tab count tab significance. BEFORE THAT********** edit the significance calculation to include percentage rather than raw count (convert all raw counts to percentages, add that as another column in the significance output)

This one is for the treatment files:
[yoccaala@dev-intel14 jellyfish]$ qsub -t 1-72 -v INFILE=fa_file_list.txt fa_to_one_liner.sh
51058897[].mgr-04.i
51059008[].mgr-04.i
51059585[].mgr-04.i
51065522[].mgr-04.i



Going to do an all v all blast search of enriched kmer files against database of known motifs and see what happens
>Athb-1 is listed twice, once with a sequence, and once without, so just removed the empty one in the hpcc copy, otherwise, fails to build db


$ module load BLAST/2.2.26
[yoccaala@dev-intel14 blast_run]$ dos2unix MotifsPlantPanCH2_Database.txt
dos2unix: converting file MotifsPlantPanCH2_Database.txt to UNIX format ...
[yoccaala@dev-intel14 blast_run]$ formatdb -i MotifsPlantPanCH2_Database.txt -p F -o T -n Motifs_db

EXAMPLE FROM qsub_blastall_ZMB73_TIGR.sh:
cd /mnt/home/yoccaala/01_VanBuren/mcscan/MCScanX/data
module load BLAST
blastall -p blastp -d "ZmB73_db Osativa_db_TIGR Bdistachyon_192_db Sbicolor_79_db" -i ZmB73_peptide.fa -e 1e-5 -b 5 -v 5 -m 8 -o ZmB73.blast3

[yoccaala@dev-intel14 blast_run]$ qsub -t 1-24 -v INFILE=file_list.txt sig_to_fa.sh
51078670[].mgr-04.i
51078723[].mgr-04.i
51078741[].mgr-04.i
51080427[].mgr-04.i
51086324[].mgr-04.i

$ blastall -p blastn -d "MotifsPlantPanCH2_Database.txt" -i treat_sig_fa/at_cold_down_inf_dump_5_sig.fa -e 1e-5 -b 5 -v 5 -m 8 -o blast_output/at_cold_down_inf_dump_5.blast

[yoccaala@dev-intel14 blast_run]$ qsub -t 1-24 -v INFILE=sig_file_list.txt blast_sig_treat_to_motif.sh
51082262[].mgr-04.i

since query is so short (5 nt since doing 5mers at the moment), need to add -W flag which sets word length. not entirely sure what that means but the default is 11 and since our query is 5, its finding zero hits, found some post recommending setting this to half the query length, but the minimum is 4, so we are sticking with that

lowest E value obtained seems to be 5.1, probably lowest posible with 5 nt query. Lets start creating the 7mer permutation files then while trying to parse through this blast output

[yoccaala@dev-intel14 Permutations]$ qsub -t 1-1000 -v INFILE=perm_file_list.txt jellyfish_7.sh
51086556[].mgr-04.i
aa

1-11-18

[yoccaala@dev-intel14 blast_run]$ qsub -t 1-24 -v INFILE=file_lists/cut_file_list.txt cut_sig.sh
51161149[].mgr-04.i
51161339[].mgr-04.i

make histogram of significance values. whats best way to remove NAs? grep not matching, yea

- make sub genome exp into table
- Think about tracking CNS changes, whats informative?
- What does this putative function list tell me?
	- What sort of comparisons should I be making across all 8 files within stress / over/underrepresentation. 
	-What are the expected functions of kmers overrep in non-responsive genes (since there are so few compared to the changed exp ones **********MAKE A TABLE********* perhaps they are just showing up there because they do show a change, but edgeR filters are too stringent, interesting to directly compare FPKM of genes in that category, might be too cyclical as far as tracking those genes down, might just be easier to lower constraints and rerun edgeR, that would be good because I would learn how to use it too, look that up later

PUTATIVE FUNCTION, COULD B DIFF FUNCS SHARE 7 BP CONSENSUS BC GOOD FOR TF BINDING


reading the Shui paper again, Those that don't respond anymore have lost the cis elements, genes that lost response to one stress, gained response to another. Rates of expression response changes decrease over evolutionary time. The proportion of nonfunctionalization of copies increases over evolutionary time. 

- Larger effective population size may result in greater duplicate exp divergence

- presence of broad spectrum cis elements over rep in pairs showing Asy=1 (one ancestral, other loss) compared to pairs showing symmetric response, thats interesting, you would think the broad responsive elements would maintain symmetry, they argue the differential loss of these broad responsive elements may be responsible for asymmetric response
- sub-neofunctionalization, neofunct usually occurs on duplicate that did not inherit the ancestral response, but duh kind of right? has to lose original function most likely first, if accumulating mutations randomly, going to do bad before you do good? IT CANT BE A RANDOM PROCESS, I ALMOST REFUSE TO BELIEVE IT, MAYBE I NEED TO RETHINK THE NUMBERS BUT NO WAY RANDOM MUTATIONS RESPONSIBLE FOR EVERYTHING WE SEE TODAY, MAYBE THE NUMBERS ARE SMALLER THAN I THINK BUT DAMN, CANT BE COMPLETELY RANDOM. Big innovations have to be non-random, right?


*****THINK OF how to find out if those that lost response to one stress, gained response to another************
- What other informative comparisons could I make? Only compared the up regulated to nonup, and down regulated to nondown
- find a way to quickly access the gene lists, ie, list of genes that are upregulated / downregulated... Actually should have that file somewhere, right? If not should be straight forward to pull from edgeR output
- look at genes with most interesting motif hits, see if their exp difference is >> than those with seemingly background ubiquitous motifs

1-19-18:

- create list of kmers that are over represented that do not have a blast hit:
	- grep for "Query: 1" will give the 7mer alignment, cut field 3 based on space delimiter, need to uniq within that file
	- put into file that has blast_7mer
	- check if there is a unix way to get unique between that and the significance file, if not write perl script
	
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-48 -v INFILE=file_lists/blast_file_list.txt ext_kmer_from_blast.sh
51419109[].mgr-04.i

	- this should put _blast_7mer.txt files into blast_run/sig_7/kmer_blast_hit/ directory containing files that have "Query: 1 kmer" for all kmer hits in blast
	- upon first look at at_cold_down_comp seem have 80 significant over rep kmers getting a blast hit to the motif db out of 890 total significantly over rep kmers. Perhaps I should rerun blast allowing up to two mismatches, that will be interesting to see what our list of "novel" kmers goes down to. 
	- side note, there are about 16k possible kmers and we get 890 ( ~5%) significant, while that seems random, we get ~5% total kmers significant but a much higher % of the kmers present only in that treatment. Still something thats going to bother me. Here is a bright side, if the stress was a random sample, then you would expect only 5% of sample to be significant, or about 2.5% of the total possible kmers (since ~ 9k kmers in each treatment), check to make sure when made sig files that it has all kmers in the treatment files, well really what about the NAs I have in my sig files, where did those come from?
	
	next step is add cut to above script to get only the kmer
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-48 -v INFILE=file_lists/blast_file_list.txt ext_kmer_from_blast.sh
51469932[].mgr-04.i

fixed that script to extract kmer substring, will be in all lowercase letters.. see if I can change that.. also should be able to deal with non-exact matches in the kmer. currerntly blast run made 100% match but later if I want non exact (i just have it taking the hyphens out)

51470917[].mgr-04.i

looks like its excluding some lines, debugging

51471466[].mgr-04.i
51472056[].mgr-04.i

awk -F " " '{print $3}' at_cold_down_comp_dump_7_sig_over_blast_7mer.txt | cat > temp.txt

use awk instead of cut

51472092[].mgr-04.i
51474061[].mgr-04.i


made put_7mers.pl now need to integrate that into bash shell for ext kmers from blast for a one step process

 at_cold_down_comp_dump_7_sig_over.blast
 at_cold_down_comp_dump_7_sig_over.fa

qsub -t 1-48 -v INFILE=file_lists/blast_file_list.txt ext_kmer_from_blast.sh
51488148[].mgr-04.i
51488158[].mgr-04.i
51490336[].mgr-04.i
51490514[].mgr-04.i
51491097[].mgr-04.i
51492287[].mgr-04.i

currently searching for DHS dataset under stress conditions... not finding it, you hate to see that
There are DHS data sets for development, dark treated, heat shocked as of 2015, haven't found any more recent than that

There is a paper that called motifs based on DHS sites and found ~70% of those in microarray data, check how they found that because there are definitely stress microarray data floating around "motif models derived from protein binding microarrays" ahhh that was the specific wording, check what thats all about.

http://cisbp.ccbr.utoronto.ca/ eukaryotic dna binding domain motif identification

After that, look for yeast 2 hybrids

***********************
for the high-throughput yeast 1H systems, prey plasmids will be easy since ~2k TFs in athal, so only 2k preys, but need to bait whole genome, do they just randomly insert and screen? actually sounds right, but how long of a bait sequence do you need to accurately map it back to the genome, actually, shouldn't 150 / 200 bp be enough?
**************************
- Michelle Tang

The sig files did not contain every significant kmer. Additionally, I have been ignoring NAs in the significance files which truely mean they are not represented in the treatment genes. These need to be considered zeros, so need to replace NA with zeros... something I could have done in R so if I run this process again separately I will need to change that since now I am jus going to write it into the perl scripts. Write my pipeline before I do any of this: actually, would be best to just replace NAs with zero, shouldn't be too difficult, yea also,,, yea just recreate the sig files again

- looked at it again, I am missing a kmer in my permutations file (16383 / 16384)
- Also, at least 1 permutation does not represent a kmer in ALL except 430 kmers. Therefore, when treatment count is zero, ecdf can = 0.5 if half of all permutations do not have that kmer..... maybe I need to step up the number of permutations... was taking 2k CNSs a good proxy? How can I get a summary table of the number of bp extracted from stress responsive / nonresponsive genes?

- checked, depending on the stress, have about 200, 400, or 700 CNSs for each treatment, took 1000 for permutations, shouldn't matter should it? decreases my confidence in meja kmers since they are smaller sample size (but then shouldn't we get more significant kmers? Ah well
~26k nt in at_cold_down_comp_cns.fa
~40k nt in perm files

-Im tempted to look for any zeros with significant ecdf and print that line to see what the permutation distribution is. shouldn't be too many lines to sift through.. sure why not??
- yea for some we are getting significance at 0 kmer counts since they are also not showing up in permutations. that I believe is because the CNSs are depleted for these kmers. Intuitively though, I should exclude these kmers. Whats a good rule? If kmer is not represented in >= 90% of permutations, exclude from further analysis? Do these kmers overlap?
3:

4:

5:


keep for now, ask later

**********scat plot between up and nonup with NA stuff**********************

	- create directory in kmer_en on hpcc backing up everything incase something goes wrong
	- R code to create _sig.txt file with five columns: kmer	treat_count	perm_min	perm_max	ecdf (sig)
	- upload to 04_Edger/kmer_en/blast_run/sig_7
	- dos2unix everything
	- create _over and _under files:
		- had previously cut out the lines with NA with cut_sig.sh using unix
		- Then had parsed it with sig_to_fa.sh / sig_to_fa.pl
			- This time, skip the cut part, edit the perl script, just take out the NA search since all NA should be zeros
	- Then blast it
		- need to think about making those up to non-up comparisons, see if they end up being the same
	- Parse blast with ext_kmer_from_blast.sh which uses put_7mers.txt
		- not sure if any information with be gained from the under rep ones but good to have anyway.
Plan:
$[yoccaala:sig_7] dos2unix *

$[blast_run] qsub -t 1-24 -v INFILE=sig_file_list.txt sig_to_fa.sh

$[blast_run] qsub -t 1-48 -v INFILE=fa_file_list.txt blast_sig_treat_to_motif.sh

$[blast_run] qsub -t 1-48 -v INFILE=blast_file_list.txt ext_kmer_from_blast.sh



[yoccaala@dev-intel14 blast_run]$ qsub -t 1-24 -v INFILE=file_lists/sig_file_list.txt sig_to_fa.sh
51519039[].mgr-04.i
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-24 -v INFILE=file_lists/cut_file_list.txt sig_to_fa.sh
51519169[].mgr-04.i
51519205[].mgr-04.i

[yoccaala@dev-intel14 blast_run]$ qsub -t 1-48 -v INFILE=file_lists/fa_file_list_over_under.txt blast_sig_treat_to_motif.sh
51519308[].mgr-04.i

[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-48 -v INFILE=file_lists/blast_file_list.txt ext_kmer_from_blast.sh
51519887[].mgr-04.i

can also get unique putative 7mers by taking out those that are also enriched in paralogs
Next step:
	- run uniq motifs
	- run uniq motif script to get unique putative 7mers

[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/put_7mer_file_list_up.txt uniq_put_7mer_up.sh
51520144[].mgr-04.i
[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/put_7mer_file_list_down.txt uniq_put_7mer_down.sh
51520161[].mgr-04.i

[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/motif_file_list_up.txt uniq_motif_up.sh
51520194[].mgr-04.i
[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/motif_file_list_down.txt uniq_motif_down.sh
51520196[].mgr-04.i

had moved the blast db to another directory after running the last time so restart from that point:
[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-48 -v INFILE=file_lists/fa_file_list_over_under.txt blast_sig_treat_to_motif.sh
51520741[].mgr-04.i

for some reason the sequence CCCCCCC and TTTTTTT is throwing out a warning, invalid query sequence??? Idk, shouldn't matter

[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/put_7mer_file_list_up.txt uniq_put_7mer_up.sh
51522140[].mgr-04.i
[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/put_7mer_file_list_down.txt uniq_put_7mer_down.sh
51522156[].mgr-04.i
[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/motif_file_list_up.txt uniq_motif_up.sh
51522157[].mgr-04.i
[yoccaala@dev-intel16-k80 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/motif_file_list_down.txt uniq_motif_down.sh
51522158[].mgr-04.i


ooopsie, these should hhave been before the uniq commands:
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-48 -v INFILE=file_lists/blast_file_list.txt ext_mot_from_blast.sh
51523041[].mgr-04.i
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-48 -v INFIL=file_lists/blast_file_list.txt ext_kmer_from_blast.sh
51523052[].mgr-04.i

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/motif_file_list_up.txt uniq_motif_up.sh
51523562[].mgr-04.i
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/motif_file_list_down.txt uniq_motif_down.sh
51523568[].mgr-04.i
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/put_7mer_file_list_up.txt uniq_put_7mer_up.sh
51523569[].mgr-04.i
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/put_7mer_file_list_down.txt uniq_put_7mer_down.sh
51523570[].mgr-04.i


ugh

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-48 -v INFILE=file_lists/blast_file_list.txt ext_kmer_from_blast.sh
51523588[].mgr-04.i
51523596[].mgr-04.i
51523611[].mgr-04.i

We are getting over 1k significantly overrep kmers. We expect 820 if its random. We only get about 100 blast hits to the db. Comparing between up / nonup will help narrow down I believe, we shall see

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/put_7mer_file_list_up.txt uniq_put_7mer_up.sh
51523844[].mgr-04.i
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists/put_7mer_file_list_down.txt uniq_put_7mer_down.sh
51523845[].mgr-04.i


Whats the expected kmer overlap between up and nonup if it was completely random? 1st sample ~ 1,500 / ~16,000. Two samples should overlap on average by that amount, right? That sounds right. Therefore,, I hope we get significantly different from that expectation

**********after incorporating the NAs as 0s, nearly doubles those significantly enriched. This tells me a significant number of genes having significant ecdf with 0 counts. NEED TO FIX THIS!!!!!!!!!!! but how? in perl script when creating fa files sounds like the best place to do it

That number doubled, but only 38 were from zeros

Ahhh, was trying to wrap my head around why such a big increase, and it was because in the first pass, I was only going through about half the rows of the whole dataframe, now I am confident we have them all. Damn its messy, need way to increase confidence in putative kmers.... maybe the scatter plots will show some cool ones

1-24-18

Lets do some scatterplots, just go from scratch here. What do we want to compare? Find a kmer that is highly represented in up that is not represented in nonup?????????????

what are the significance values of my kmers with blast hits?? That probably doesn't matter

What does the histogram of significance values look like zoomed in on the over rep ones? Can't think of a super high throughput way to do it locally so for now look within up/down and within nonup/nondown

I zoomed in on the histograms of sig values. They don't seem to really peak until after 0.99, so lets pull those out and blast them and compare some results. I will have higher confidence in both the putative 7mers and motif hits

create new directories:
	- sig_fa_7/99/ 
	- blast_output/99/ 
	- sig_7/99/kmer_blast_hit 
	- sig_7/99/put_7mer/
	- motifs/99/
	- motifs/99/uniq
	- sig_7/99/put_7mer/uniq

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-24 -v INFILE=file_lists_99/sig_file_list.txt scripts_99/sig_to_fa_99.sh
51538661[].mgr-04.i
51538746[].mgr-04.i
51538917[].mgr-04.i

The alpha dup file, sig_7/at_cold_nonup_comp_dump_5_sig.fa, does not exist.

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-24 -v INFILE=file_lists_99/file_list_7.txt scripts_99/sig_to_fa_99.sh
51539095[].mgr-04.i

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_99/fa_file_list_99.txt scripts_99/blast_sig_treat_to_motif_99.sh
51539377[].mgr-04.i

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_99/blast_file_list_99.txt scripts_99/ext_kmer_from_blast_99.sh
51539645[].mgr-04.i

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_99/blast_file_list_99.txt scripts_99/ext_mot_from_blast_99.sh
51539702[].mgr-04.i


[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_up_99.txt scripts_99/uniq_motif_up_99.sh
51539941[].mgr-04.i
51539946[].mgr-04.i
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_down_99.txt scripts_99/uniq_motif_down_99.sh
51539943[].mgr-04.i
51539947[].mgr-04.i
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_up_99.txt scripts_99/uniq_put_7mer_up_99.sh
51539944[].mgr-04.i
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_down_99.txt scripts_99/uniq_put_7mer_down_99.sh
51539945[].mgr-04.i


Need to think of a nice way to present the information / should download the summary tables so they can all be open at the same time for sure. Do that first, get histograms ready first. Need to think about scatter plots stuff. Is there anything that I should read like right now? I read about 3 papers per week just dallying around. class not really that stressfull (except maybe tonight) so I have time for all this stuff.



Summary tables did not have all 24 files in them. I think it was a problem with the multithreading not able to open and write simultaneously. Think can sove it by having perl script save to uniq temp file and use cat to append to bigger file

How to align them easily?? What do I want final product to look like?

0.95	0.99
#change	#change
#non	#non

I think the best way will be to make a tab separated file where you get file name with base info: stress,edgeR,comp/inf,over/under,motif/put7mer,99/95

These are going to be some very specific loops might not be very useful later. Meeting is soon so just manually curate a few for comparison then create final table later. good to ask now though: what do we want the table to tell us? How much info changed moving from 0.95 to 0.99, how many putative 7mers / blast motif hits do we have



Hardly any motif # change!!!! (this comment coming much later. there is still little change, but i was excited about getting exact #s, however i did not change underrep threshold so all underrep were showing same exact #s) So our kmers that blasted to motifs were almost exclusively in this >0.99 bin which is great!!!!
Seems like very large amount of putative 7mers still..... that will be tough to tease out. Lets see how many 7mers we were blasting in the >0.99 set

- Y1H data to see if put 7mers have protein binding evidence

copy number of kmer called (redo scatter plots to be sure and so you have them)

- Type up overview to stare at
- expect clustering. superimpose on gene coexp network
- rank confidence in shift between them. look for most extreme differences. think about how they compare the permutations. ~ 10 CNSs to look at manually. grab from skew could randomly pick 10


fix summary tables:
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_up_99.txt scripts_99/uniq_motif_up_99.sh
51544877[].mgr-04.i
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_down_99.txt scripts_99/uniq_motif_down_99.sh
51544878[].mgr-04.i
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_up_99.txt scripts_99/uniq_put_7mer_up_99.sh
51544879[].mgr-04.i
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_down_99.txt scripts_99/uniq_put_7mer_down_99.sh
51544880[].mgr-04.i

that didn't work, new idea, only give it a single processor  / thread

[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_up_99.txt scripts_99/uniq_motif_up_99.sh
51545194[].mgr-04.i
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_down_99.txt scripts_99/uniq_motif_down_99.sh
51545195[].mgr-04.i
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_up_99.txt scripts_99/uniq_put_7mer_up_99.sh
51545196[].mgr-04.i
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_down_99.txt scripts_99/uniq_put_7mer_down_99.sh
51545197[].mgr-04.i

:( should also run up / down separately ie make sure one finished first

[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_up_99.txt scripts_99/uniq_motif_up_99.sh
51546472[].mgr-04.i
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_up_99.txt scripts_99/uniq_put_7mer_up_99.sh
51546504[].mgr-04.i

wait a little

WHAT IS GOING ON!? try changing opening method

Chad strong candidate: emily josephs: Ning Jiang: Jiming Jiang: Kevin Leui (comp sci maybe) Some strong stat component: Shinhan: Jeff connor or gidean: marjorie Weber

- Get deadline for committee formation

- cns in tandem much closer than further ones


[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_down_99.txt scripts_99/uniq_motif_down_99.sh
51568715[].mgr-04.i
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_down_99.txt scripts_99/uniq_put_7mer_down_99.sh
51568730[].mgr-04.i


[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_up_99.txt scripts_99/uniq_put_7mer_up_99.sh
51569985[].mgr-04.i
[yoccaala@dev-intel14 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_down_99.txt scripts_99/uniq_put_7mer_down_99.sh
51569988[].mgr-04.i


DAP-seq data set with putative motifs for >500 TFs, can see what we get hits to I guess. Cant think of a good way to compare, can blast but they are all in meme format so have probabilities of given nucleotides, must be some way to convert that all into a file like the one of >300 I have, yea ask Pat about that
Therefore it would be:
- create a file similar to what I have for the 300 but with the DAP-seq data, just a little bit more of a way to narrow down the list

What do I want to find? I want to demonstrate paralogs differ in their stress responsiveness due to differential CNSs. Need to show they are different and show that CNSs in responsive paralogs are significantly associated with upregulation. Would also be awesome of copy number diff of TF binding site had something to do with it


1-26-18

as much as i hate to say it, i should redo my perms with just the cnss found in the alpha dup set
Regardless, I should make a file with the CNSs of just the alpha duplicates

High confidence set of kmers significantly associated with stress response:
	- first get all with significance value of one, then do I guess histogram of the significance values of these kmers in their paralogs, look for the smallest bin possibly? That sounds good. Nice, got two coding projects ahead for me. At the same time, try to make those tables whole (unique motifs / putative 7mers. I think I can do it, now going to have up / down written to separate files then just combine them manually)
	
	
[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_up_99.txt scripts_99/uniq_motif_up_99.sh
51663269[].mgr-04.i
51665714[].mgr-04.i

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/motif_file_list_down_99.txt scripts_99/uniq_motif_down_99.sh
51663272[].mgr-04.i
51665727[].mgr-04.i

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_up_99.txt scripts_99/uniq_put_7mer_up_99.sh
51663274[].mgr-04.i
51665742[].mgr-04.i

[yoccaala@dev-intel14-k20 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_99/put_7mer_file_list_down_99.txt scripts_99/uniq_put_7mer_down_99.sh
51663280[].mgr-04.i
51665752[].mgr-04.i

screw it, just going to combine all temp files manually at the end


1400 alpha duplicate pairs, 2800 genes total


Pipeline for running permutation kmer counts to the point of getting significance files

	- Take permutations in R
	- upload to hpcc in alpha_permutations/ directory
	- run jellyfish.
		- create jellyfish/ directory within alpha perm
		- create perm_file_list
		- qsub -t 1-1000 -v INFILE=perm_file_list.txt jellyfish_7.sh
		- will output into jellyfish file a list of dump and .fa files
		- need to convert those .fa files to one liners
			- fa_to_one_liner.sh (uses fa_to_one_liner.pl)
			- make directory one_liners/ within jellyfish to put these in to
		- I think after that download locally for sig calculations
		
[yoccaala@dev-intel14-k20 alpha_Permutations]$ qsub -t 1-1000 -v INFILE=aperm_file_list.txt jellyfish_7.sh
51683820[].mgr-04.i
51684109[].mgr-04.i

jellyfish count -m 7 -s 100M -t 1 -o jellyfish/${NAME}binary_7.jf ${LINE}

jellyfish dump jellyfish/${NAME}_binary_7.jf_0 > jellyfish/${NAME}_dump_7.fa
 segmentation fault, core dumped look up later

1-29-18

segmentation fault was due to repeat sequences in permutation files, really impressed there were no duplicates in the other permutations. Took 1000 out of 65k so little prob of overlap, but out of 1k reps you would think it would have happened at least once. Ah well, I think taking the random samples without replacement will be fine, actually will probably be beetter than with replacement

turned out to be dos2unix thing, didn't do that so was getting segmentation fault, I think rolling without replacement still the better way to go though

[yoccaala@dev-intel14-k20 alpha_permutations]$ qsub -t 1-1000 -v INFILE=file_list_aperm.txt jellyfish_7.sh
51896713[].mgr-04.i

aperm_106_binary_7.jf_0
aperm_1000binary_7.jf_0

51897273[].mgr-04.i


[yoccaala@dev-intel14-k20 alpha_permutations]$ qsub -t 1-1000 -v INFILE=jellyfish/file_list_fa.txt fa_to_one_liner.sh
51905975[].mgr-04.i

[yoccaala@dev-intel14-k20 alpha_permutations]$ qsub -t 1-1000 -v INFILE=file_list_fa.txt fa_to_one_liner.sh
51906885[].mgr-04.i

If this doesn't work, just move all the fa to one line stuff into jellyfish folder and submit from there, should have done that in the first place, yup gotta do that

[yoccaala@dev-intel14-k20 jellyfish]$ qsub -t 1-1000 -v INFILE=file_list_fa.txt fa_to_one_liner.sh
51911620[].mgr-04.i

The qsub script was taking to the wrong directory, fixed it to go to alpha_permutations
51911972[].mgr-04.i

Nice, starting to work, now we have files (eg  aperm_10_dump_7_one.fa). That have kmer\tcount
I believe the next steps to create the significance files are done locally in R, now I am faced with the problem of having all those that are in the treatment but not the permutations represented... hold on, no way not going to find all possible kmers across 1k permutations, right?? like not a single time? we shall see, start setting up in R, going to take maybe an hour to create the one liners

Something seemed to screw up around the 200th round. I think it was just a technical error, but the perl script was printing the usage statement. That means some command line argument was missing. Therefore, I added to the qsub script to print out all the environmental variables at the end, so if something is missing, I can see what / when it starts to be missing


51916876[].mgr-04.i
51917253[].mgr-04.i

fa file list only had 135 lines for some stupid reason

51918558[].mgr-04.i

		
		
		
1-30-18

Histogram of all significance values as well as >0.95
histograms of non and changes look fairly similar, this is evidence that they do contain overrep sequences, but it seems these over rep kmers are not sufficient to cause change. Again, perhaps edgeR is too stringent, or maybe we have to dig deeper. Definitely seems like non-responsive paralogs will have these kmers at high counts. Maybe that's not whats causing the response / non-response. Lets find a list of genes with similar CNS (how to measure) but also different responses. First check exp level and see if they are really close anyway. If they are divergent, will be interesting to overlay some methylation data.


Based on the > 0.95 histograms, looks like we should take 0.99 as cutoff again. Keep underrep at <0.05
Meja looks like only stress with high abundance underrep sequences, but that could just be that the over rep are so abundant


Make the following directories withint blast_run/
	- scripts_alpha
	- file_lists_alpha
	- asig_7/put_7mer/uniq
	- asig_fa_7
	- blast_output/asig/
	- motifs/alpha/uniq
	- asig_7/kmer_blast_hit
	
Blast against ~300 known motifs

	- Convert significance files in asig_7/ to fa files with sig values >0.99 (over) or <0.05 (under)
		- sig_to_fa_99.pl / sig_to_fa_99.sh (I think I can mostly use the same sh scripts just changing INFILE.. Ah, some of them specify where to save files, in that case need to edit and replace 99 with alpha
	- Blast against motifs
		- blast_sig.sh
	- ext mot / ext put 7mers
	- check diagnostics
	- check concordance between alpha / overall permutation put7mers, if that isn't making sense back up a few steps, try to get a good picture of what is going on (HOPEFULLY NOT RANDOM)
	
Keep track of what my file names are:
./sig_to_fa_99.pl -i asig_7/${LINE} -o asig_fa_7/${NAME}_asig_over.fa -u sig_fa_7/${NAME}_asig_under.fa

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-24 -v INFILE=file_lists_alpha/asig_file_list.txt scripts_alpha/sig_to_fa_alpha.sh
51965118[].mgr-04.i
51965214[].mgr-04.i

blastall -p blastn -d "database/Motifs_db" -i asig_fa_7/${LINE} -e 0.5 -o blast_output/asig/${NAME}.blast -W 4

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_alpha/fa_alpha_file_list.txt scripts_alpha/blast_sig_treat_to_motif_alpha.sh
51965299[].mgr-04.i


[yoccaala@dev-intel16 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_alpha/blast_alpha_file_list.txt scripts_alpha/ext_mot_from_blast_alpha.sh
51967119[].mgr-04.i
51967293[].mgr-04.i
51967310[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_alpha/blast_alpha_file_list.txt scripts_alpha/ext_kmer_from_blast_alpha.sh
51967126[].mgr-04.i

grep '^Query: 1 ' blast_output/asig/${LINE} | sort | uniq | awk -F " " '{print $3}' | sed 's/-//g' | tr '[:lower:]' '[:upper:]' | cat > asig_7/kmer_blast_hit/${NAME}_blast_7mer.txt
# cut -d" " -f 3 | sed 's/-//g'

./put_7mers.pl -i asig_fa_7/${NAME}.fa -j asig_7/kmer_blast_hit/${NAME}_blast_7mer.txt -t temp_${PBS_ARRAYID}.txt -o asig_7/put_7mer/${NAME}_put_7mer.txt

grep '^>' blast_output/asig/${LINE} | sort | uniq | cat > motifs/asig/${NAME}_motif.txt

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/motif_up_alpha_file_list.txt scripts_alpha/uniq_motif_up_alpha.sh
51967516[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/motif_down_alpha_file_list.txt scripts_alpha/uniq_motif_down_alpha.sh
51967517[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/put_up_alpha_file_list.txt scripts_alpha/uniq_put_7mer_up_alpha.sh
51967518[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/put_down_alpha_file_list.txt scripts_alpha/uniq_put_7mer_down_alpha.sh
51967521[].mgr-04.i


Cannot open the input file asig_7/put_7mer/at_cold_up_comp_dump_7_asig_under_blast_7mer.txt
	- ext_kmer_from_blast script did not complete, should have made file set in asig_7/put_7mer directory
Cannot open the input file motifs/asig/at_salt_up_comp_dump_7_asig_over_motif.txt
	- wrong file path specified in ext_motif script, quick fix
	
rerun ext_kmer first

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_alpha/blast_alpha_file_list.txt scripts_alpha/ext_kmer_from_blast_alpha.sh
51967954[].mgr-04.i

went well

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/motif_up_alpha_file_list.txt scripts_alpha/uniq_motif_up_alpha.sh
51968033[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/motif_down_alpha_file_list.txt scripts_alpha/uniq_motif_down_alpha.sh
51968034[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/put_up_alpha_file_list.txt scripts_alpha/uniq_put_7mer_up_alpha.sh
51968035[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/put_down_alpha_file_list.txt scripts_alpha/uniq_put_7mer_down_alpha.sh
51968036[].mgr-04.i

Cannot open the input file asig_7/put_7mer/at_cold_up_inf_dump_7_asig_under_blast_7mer.txt

at_cold_up_comp_dump_7_asig_over_blast_7mer.txt
at_salt_up_inf_dump_7_asig_under_put_7mer.txt

./put_7mers.pl -i asig_fa_7/${NAME}.fa -j asig_7/kmer_blast_hit/${NAME}_blast_7mer.txt -t temp_${PBS_ARRAYID}.txt -o asig_7/put_7mer/${NAME}_put_7mer.txt

./uniq_motif.pl -c asig_7/put_7mer/${LINE} -n asig_7/put_7mer/${NON} -o asig_7/put_7mer/uniq/${NAME}_uniq.txt -t asig_7/put_7mer/uniq/${NON_NAME}_uniq.txt -s temp_put_up_${PBS_ARRAYID}.txt

change file list from those in kmer_blast_hit to those in put_7mer

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/put_up_file_list.txt scripts_alpha/uniq_put_7mer_up_alpha.sh
51968518[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-12 -v INFILE=file_lists_alpha/put_down_file_list.txt scripts_alpha/uniq_put_7mer_down_alpha.sh
51968519[].mgr-04.i

Alrighty, now lets make a table comparing numbers of sig put kmers in global and alpha
want to see the overlap between the two, cat into one file, then do uniq and wc -l

at_salt_nonup_comp_dump_7_sig_over_99_put_7mer_uniq.txt
at_salt_nonup_comp_dump_7_asig_over_put_7mer_uniq.txt

file lists of one, replace sig with asig, remove 99, make base everything before dump
	
grep -f sig_7/99/put_7mer/uniq/${LINE} asig_7/put_7mer/uniq/${ALPHA} | cat > put_7mer_comp/${BASE}_put_7mer_shared.txt

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-48 -v INFILE=put_comp_file_list.txt put_7mer_comp.sh
51970428[].mgr-04.i



Lets pull kmers with sig value of 1 (*) whose paralog has a count of 0 (info should be in the significance files) see how many kmers we are left with at that point

*should I do 1, then the highest copy number, or just above a certain copy number? I think starting with 1 and seeing how many we are left with is a good place to start

Alrighty, method of outputting a list of kmers \t responsive paralog sig value \t responseive paralog count \t non-responsive paralog count
for each pair of response/non, although later should consider other methodology for downregulated genes maybe???

	- open responsive significance file
	- extract lines with sig value = 1
	- take those kmers to find in the paralog significance file
	- filter to include those with count of zero in paralog file
	- print out desire information
	
Seems like I can do this in perl script, input up / nonup files, output final file, loading things into hash

my $usage = "\n$0 -i <responsive file> -n <non-responsive file> -o <output> \n\n";

high_conf_kmer.pl

at_cold_down_comp_dump_7_one.fa_asig.txt

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-6 -v INFILE=high_conf_up_file_list.txt high_conf_kmer_up.sh
51971383[].mgr-04.i
51971432[].mgr-04.i
51971474[].mgr-04.i
51971527[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-6 -v INFILE=high_conf_down_file_list.txt high_conf_kmer_down.sh
51971390[].mgr-04.i
51971434[].mgr-04.i
51971479[].mgr-04.i
51971528[].mgr-04.i


hmmm, looks like im not really recovering anything. First add some statements to see if its working properly, then think about how to lower stringency


my %sig_kmer;
my %sig_kmer_count;
my $lines_resp = 0;
my $lines_non = 0;
my $sig_one = 0;
my $found_kmer = 0;
my $all_met = 0;


[yoccaala@dev-intel16 blast_run]$ qsub -t 1-6 -v INFILE=high_conf_up_file_list.txt high_conf_kmer_up.sh
51972578[].mgr-04.i
[yoccaala@dev-intel16 blast_run]$ qsub -t 1-6 -v INFILE=high_conf_down_file_list.txt high_conf_kmer_down.sh
51972587[].mgr-04.i

Lines read from asig_7/at_meja_up_comp_dump_7_one.fa_asig.txt:  16108
Lines read from asig_7/at_meja_nonup_comp_dump_7_one.fa_asig.txt:       0
		       at_meja_nonup_comp_dump_7_one.fa_asig.txt
 aha, first round, I had the perl script open these ones for writting so must have overwritten the files, reupload and try again

51972755[].mgr-04.i

51972763[].mgr-04.i

Heyoo, this one worked fine
Line counts for the output files, subtract one for the header and get # of kmers with sig value 1 and absent in the paralog
   79 at_cold_down_comp_dump_7.fa_asig.txt_one_and_none.txt
   91 at_cold_down_inf_dump_7.fa_asig.txt_one_and_none.txt
  103 at_cold_up_comp_dump_7.fa_asig.txt_one_and_none.txt
  104 at_cold_up_inf_dump_7.fa_asig.txt_one_and_none.txt
  634 at_meja_down_comp_dump_7.fa_asig.txt_one_and_none.txt
  634 at_meja_down_inf_dump_7.fa_asig.txt_one_and_none.txt
 1092 at_meja_up_comp_dump_7.fa_asig.txt_one_and_none.txt
 1092 at_meja_up_inf_dump_7.fa_asig.txt_one_and_none.txt
  129 at_salt_down_comp_dump_7.fa_asig.txt_one_and_none.txt
  133 at_salt_down_inf_dump_7.fa_asig.txt_one_and_none.txt
   93 at_salt_up_comp_dump_7.fa_asig.txt_one_and_none.txt
   96 at_salt_up_inf_dump_7.fa_asig.txt_one_and_none.txt

manually check the files, sort and find the highest few copy numbers:

8  at_cold_down_comp_dump_7.fa_asig.txt_one_and_none.txt
8  at_cold_down_inf_dump_7.fa_asig.txt_one_and_none.txt
7  at_cold_up_comp_dump_7.fa_asig.txt_one_and_none.txt
7  at_cold_up_inf_dump_7.fa_asig.txt_one_and_none.txt
7  at_meja_down_comp_dump_7.fa_asig.txt_one_and_none.txt
7  at_meja_down_inf_dump_7.fa_asig.txt_one_and_none.txt
5  at_meja_up_comp_dump_7.fa_asig.txt_one_and_none.txt
5  at_meja_up_inf_dump_7.fa_asig.txt_one_and_none.txt
9  at_salt_down_comp_dump_7.fa_asig.txt_one_and_none.txt
9  at_salt_down_inf_dump_7.fa_asig.txt_one_and_none.txt
9  at_salt_up_comp_dump_7.fa_asig.txt_one_and_none.txt
9  at_salt_up_inf_dump_7.fa_asig.txt_one_and_none.txt


1-31-18

How many putative kmers do I cut down on by allowing one mismatch on BLAST????
blastall -p blastn -d "database/Motifs_db" -i sig_fa_7/99/${LINE} -e 0.5 -o blast_output/99/${NAME}.blast -W 4

change e-value cutoff to 0.94 (6 bp match). (put -e 1 in script)
0.24 is 7 bp match, 3.7 is 5 bp match

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_alpha/fa_alpha_file_list.txt scripts_alpha/blast_sig_treat_to_motif_alpha_6.sh
52005168[].mgr-04.i

Don't really care about getting motif names and what not, just care about put 7mers, so not making any motif 6 directories

After blast is done, ext_kmer, then uniq_put_7mer

Seems files ~50% larger. surprisingly taking a while to run, check usage request, make sure will not exceed walltime
6hr 15 processors across 5 nodes, 10Gb mem, should be fine, just taking a bit

Need to give thought of how going to present high confidence genes (I think I should get to the level of genes)

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_alpha/blast_6_file_list.txt scripts_alpha/ext_kmer_from_blast_alpha_6.sh
52011624[].mgr-04.i
52012381[].mgr-04.i

Meeting today present:
	- alpha permutations
	- New set of putative 7mers
	- hand picked list of genes:
		- highest kmer count in repsonsive that has sig=1, while non-responsive paralog has 0
	- What do put 7mer counts look like after matching at least 6bp instead of all 7?
	- NEXT STEPS:
		- Should I include the DAP-seq info?
			- screened 1800 TF
			- had them on beads, threw DNA at them, sequenced what bound
			- Predicted binding motifs for ~500 TFs
				- binding info in MEME format
				- IF cont with this, should call motif based on cutoffs, include every bp with probability > 0? have example file open and ready
		- Check out hand picked genes
		- Not too sure how much I can do with this? Is this enough of a story? No, need to start integrating CV data
			- But CV data really vague, really only have about 10 responsive orthologs per treatment, actually, get those numbers:
				- Complete set of genes:
				- Cold: 135
				- Salt: 984
				- Meja: 738
				- Alpha Orthologs
				- Cold: 17
				- Salt: 70
				- Meja: 63
				
			- Is there any way to see CNS in CV, can we say some TF binding sites were gained de novo or lost in responsive duplicates? What info do we want to pull out?
			- Is it safe to assume CV is ancestral state? 
				- If so, then can pull out informative genes, and really just pull out the CNS and compare them right?
					- Align, look for mutations / indels
			
			
To do:
- Gene lists for high abundant kmers, do at least 5
- Get at least 5 consecutive bp calls, do 0.8 threshold
- Network modularity
- Do less Cv stuff
- Think about think tank stuff
- read 6 papers
- Compare bin frequencies across duplication classes across several species in 65k (TF probably distal elements, so when duplicated, instant psuedogene) 

Network connectivity implications:
- Gene and genome duplications the impact of dosage-sensitivity on the fate of nuclear genes


Blast 6 file list:   at_cold_down_comp_dump_7_asig_over_6.blast
Need asig_fa_7 file: at_cold_down_comp_dump_7_asig_over.fa

[yoccaala@dev-intel16 blast_run]$ qsub -t 1-48 -v INFILE=file_lists_alpha/blast_6_file_list.txt scripts_alpha/ext_kmer_from_blast_alpha_6.sh
52013701[].mgr-04.i


for f in $(find motifs/ -name 'meme_m1.txt'); do echo $f; done 

Thank you stack overflow

instead of do echo $f, see if can write in perl script




